import os, datetime as dt, math
from datetime import timedelta
import httpx
import feedparser
from openai import OpenAI

OPENAI = os.getenv("OPENAI_API_KEY")
CHAT_MODEL = os.getenv("CHAT_MODEL", "gpt-4o-mini")
ECOS_KEY = os.getenv("ECOS_KEY")
FRED_KEY = os.getenv("FRED_KEY")

# ---------------- RSS ë‰´ìŠ¤ ìˆ˜ì§‘ (ë¬´ë£Œ) ----------------
async def fetch_rss_news(kind: str) -> list[dict]:
    """
    RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    âš ï¸ STUB ì œê±°: ì‹¤íŒ¨ì‹œ ë¹ˆ ë°°ì—´ ë°˜í™˜
    """
    news_sources = []
    
    try:
        # 1. ì—°í•©ë‰´ìŠ¤ RSS
        yna_feed = feedparser.parse("https://www.yna.co.kr/rss/all.xml")
        for entry in yna_feed.entries[:5]:
            news_sources.append({
                "title": entry.get("title", "ì œëª© ì—†ìŒ"),
                "url": entry.get("link", ""),
                "source": "ì—°í•©ë‰´ìŠ¤",
                "date": entry.get("published", "")
            })
    except Exception as e:
        print(f"ì—°í•©ë‰´ìŠ¤ RSS ì˜¤ë¥˜: {e}")
    
    try:
        # 2. í•œêµ­ê²½ì œ RSS
        hankyung_feed = feedparser.parse("https://www.hankyung.com/feed/")
        for entry in hankyung_feed.entries[:5]:
            news_sources.append({
                "title": entry.get("title", "ì œëª© ì—†ìŒ"),
                "url": entry.get("link", ""),
                "source": "í•œêµ­ê²½ì œ",
                "date": entry.get("published", "")
            })
    except Exception as e:
        print(f"í•œêµ­ê²½ì œ RSS ì˜¤ë¥˜: {e}")
    
    try:
        # 3. Google News RSS (ê²½ì œ í‚¤ì›Œë“œ)
        if kind == "daily":
            query = "KOSPI OR KOSDAQ OR í•œêµ­ê²½ì œ OR ì¦ì‹œ"
        elif kind == "weekly":
            query = "ìˆ˜ì¶œ OR ë¬´ì—­ OR ì‚°ì—…ë™í–¥"
        else:
            query = "ê²½ì œì „ë§ OR ê¸ˆë¦¬ OR ì¸í”Œë ˆì´ì…˜"
        
        google_url = f"https://news.google.com/rss/search?q={query}&hl=ko&gl=KR&ceid=KR:ko"
        google_feed = feedparser.parse(google_url)
        for entry in google_feed.entries[:5]:
            news_sources.append({
                "title": entry.get("title", "ì œëª© ì—†ìŒ"),
                "url": entry.get("link", ""),
                "source": "Google News",
                "date": entry.get("published", "")
            })
    except Exception as e:
        print(f"Google News RSS ì˜¤ë¥˜: {e}")
    
    # âš ï¸ STUB ì œê±°: ì‹¤íŒ¨ì‹œ ë¹ˆ ë°°ì—´ ë°˜í™˜
    if not news_sources:
        print("âš ï¸ ëª¨ë“  RSS í”¼ë“œ ì‹¤íŒ¨ - ë¹ˆ ë°°ì—´ ë°˜í™˜")
        return []
    
    return news_sources[:10]  # ìµœëŒ€ 10ê°œ ë°˜í™˜

# ---------------- FRED helpers ----------------
async def fred_latest(series_id: str):
    """FRED APIì—ì„œ ìµœì‹  ê°’ ì¡°íšŒ"""
    if not FRED_KEY: 
        print(f"âš ï¸ FRED_KEY ì—†ìŒ - {series_id} ì¡°íšŒ ë¶ˆê°€")
        return None
    url = f"https://api.stlouisfed.org/fred/series/observations?series_id={series_id}&api_key={FRED_KEY}&file_type=json&sort_order=desc&limit=1"
    try:
        async with httpx.AsyncClient(timeout=20) as client:
            r = await client.get(url)
            r.raise_for_status()
            j = r.json()
        obs = j.get("observations", [])
        if not obs: return None
        o = obs[0]
        return {"date": o.get("date"), "value": o.get("value")}
    except Exception as e:
        print(f"FRED API ì˜¤ë¥˜ ({series_id}): {e}")
        return None

async def fred_historical(series_id: str, days: int = 30):
    """
    FRED APIì—ì„œ íˆìŠ¤í† ë¦¬ì»¬ ë°ì´í„° ì¡°íšŒ
    - days: ìµœê·¼ ë©°ì¹ ê°„ì˜ ë°ì´í„° (ê¸°ë³¸ 30ì¼)
    - ë°˜í™˜: [{"date": "YYYY-MM-DD", "value": float}, ...]
    """
    if not FRED_KEY:
        print(f"âš ï¸ FRED_KEY ì—†ìŒ - {series_id} íˆìŠ¤í† ë¦¬ì»¬ ì¡°íšŒ ë¶ˆê°€")
        return []
    
    end_date = dt.datetime.now().date()
    start_date = end_date - timedelta(days=days)
    
    url = (
        f"https://api.stlouisfed.org/fred/series/observations"
        f"?series_id={series_id}"
        f"&api_key={FRED_KEY}"
        f"&file_type=json"
        f"&observation_start={start_date.isoformat()}"
        f"&observation_end={end_date.isoformat()}"
        f"&sort_order=asc"
    )
    
    try:
        async with httpx.AsyncClient(timeout=30) as client:
            r = await client.get(url)
            r.raise_for_status()
            j = r.json()
        
        observations = j.get("observations", [])
        result = []
        for obs in observations:
            value = obs.get("value")
            date = obs.get("date")
            # "." ê°’ í•„í„°ë§ (FREDì—ì„œ ë°ì´í„° ì—†ìŒì„ ì˜ë¯¸)
            if value and value != "." and date:
                try:
                    result.append({"date": date, "value": float(value)})
                except ValueError:
                    continue
        
        return result
    except Exception as e:
        print(f"FRED íˆìŠ¤í† ë¦¬ì»¬ API ì˜¤ë¥˜ ({series_id}): {e}")
        return []

async def enrich_with_fred(data: dict) -> dict:
    """ì‹¤ì œ FRED ë°ì´í„°ë¡œ ë³´ê°• (ìŠ¤í… ì—†ìŒ)"""
    
    # ë¯¸êµ­ 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
    dgs10 = await fred_latest("DGS10")
    if dgs10 and dgs10["value"] not in (None, "."):
        data.setdefault("daily_snapshot", {}).setdefault("rates", {})["UST10Y"] = float(dgs10["value"])
    
    # ì›/ë‹¬ëŸ¬ í™˜ìœ¨
    krw = await fred_latest("DEXKOUS")
    if krw and krw["value"] not in (None, "."):
        data.setdefault("daily_snapshot", {}).setdefault("fx", {})["USDKRW"] = float(krw["value"])
    
    # ë¯¸êµ­ CPI
    cpi = await fred_latest("CPIAUCSL")
    if cpi and cpi["value"] not in (None, "."):
        data.setdefault("macro", []).append({
            "name": "US CPI (index)", 
            "latest": float(cpi["value"]), 
            "note": cpi["date"]
        })
    
    # ë¯¸êµ­ ì‹¤ì—…ë¥ 
    unrate = await fred_latest("UNRATE")
    if unrate and unrate["value"] not in (None, "."):
        data.setdefault("macro", []).append({
            "name": "US Unemployment Rate", 
            "latest": float(unrate["value"]), 
            "note": unrate["date"]
        })
    
    # ë¯¸êµ­ ì—°ì¤€ ê¸°ì¤€ê¸ˆë¦¬
    ffr = await fred_latest("FEDFUNDS")
    if ffr and ffr["value"] not in (None, "."):
        data.setdefault("macro", []).append({
            "name": "Fed Funds Rate", 
            "latest": float(ffr["value"]), 
            "note": ffr["date"]
        })
    
    # í•œêµ­ CPI (OECD/FRED)
    korcpi = await fred_latest("KORCPIALLMINMEI")
    if korcpi and korcpi["value"] not in (None, "."):
        data.setdefault("macro", []).append({
            "name": "Korea CPI (OECD/FRED)", 
            "latest": float(korcpi["value"]), 
            "note": korcpi["date"]
        })
    
    return data

# ---------------- ECOS(ì˜µì…˜) ----------------
async def ecos_korea_cpi_latest():
    if not ECOS_KEY: return None
    url = f"https://ecos.bok.or.kr/api/StatisticSearch/{ECOS_KEY}/json/kr/1/2/901Y014/M/2020/2030/"
    try:
        async with httpx.AsyncClient(timeout=20) as client:
            r = await client.get(url)
            r.raise_for_status()
            j = r.json()
        row = j["StatisticSearch"]["row"][-1]
        return {"value": float(row["DATA_VALUE"]), "date": row["TIME"]}
    except Exception as e:
        print(f"ECOS API ì˜¤ë¥˜: {e}")
        return None

async def enrich_with_ecos(data: dict) -> dict:
    kcpi = await ecos_korea_cpi_latest()
    if kcpi:
        data.setdefault("macro", []).append({
            "name": "Korea CPI (ECOS)", 
            "latest": kcpi["value"], 
            "note": kcpi["date"]
        })
    return data

# ---------------- ì…ë ¥ ë°ì´í„° êµ¬ì„± ----------------
async def build_inputs(kind: str) -> dict:
    """
    âš ï¸ STUB ì œê±°: ì‹¤ì œ ë°ì´í„°ë§Œ ìˆ˜ì§‘
    - ì‹œì¥ ìŠ¤ëƒ…ìƒ·: FRED ì‹¤ë°ì´í„°ë§Œ í¬í•¨ (stub indices ì œê±°)
    - ë‰´ìŠ¤: RSS ì‹¤íŒ¨ì‹œ ë¹ˆ ë°°ì—´
    - ë§¤í¬ë¡œ: FRED/ECOS ì‹¤ë°ì´í„°ë§Œ
    """
    today = dt.datetime.now().date().isoformat()
    
    # RSS ë‰´ìŠ¤ ìˆ˜ì§‘ (stub ì—†ìŒ)
    headlines = await fetch_rss_news(kind)
    
    # âš ï¸ STUB ì œê±°: ê¸°ë³¸ êµ¬ì¡°ë§Œ ìƒì„± (ì‹¤ë°ì´í„°ë¡œë§Œ ì±„ì›€)
    data = {
        "date": today,
        "daily_snapshot": {},  # FREDì—ì„œë§Œ ì±„ì›€
        "macro": [],           # FRED/ECOSì—ì„œë§Œ ì±„ì›€
        "headlines": headlines,
        "user_profile": {
            "risk_pref": "ì¤‘ë¦½", 
            "interests": ["ë°˜ë„ì²´", "ë¶€ë™ì‚°"]
        }
    }
    
    # ì‹¤ë°ì´í„° ë³´ê°•
    data = await enrich_with_fred(data)
    data = await enrich_with_ecos(data)
    
    return data

# ---------------- LLM í˜¸ì¶œ ----------------
async def call_llm(system_prompt: str, user_prompt: str) -> str:
    if not OPENAI:
        return (
            "**âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**\n\n"
            "í™˜ê²½ë³€ìˆ˜ `OPENAI_API_KEY`ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n\n"
            "ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ë ¤ë©´ OpenAI APIê°€ í•„ìš”í•©ë‹ˆë‹¤."
        )
    
    try:
        client = OpenAI(api_key=OPENAI)
        resp = client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3
        )
        return resp.choices[0].message.content
    except Exception as e:
        print(f"OpenAI API ì˜¤ë¥˜: {e}")
        return f"**ì˜¤ë¥˜**: OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ - {str(e)}\n\n(ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤)"

# ---------------- í•´ì„ í”„ë¡¬í”„íŠ¸ ----------------
def build_analysis_prompt(data: dict) -> tuple[str, str]:
    system = (
        "You are a Korean macro & markets analyst for one user (Junki). "
        "Style: concise, neutral, actionable. Explain terms briefly. "
        "Ground claims in provided data and links."
    )
    
    # ë‰´ìŠ¤ í—¤ë“œë¼ì¸ í¬ë§·íŒ…
    news_section = "\n\n### ğŸ“° ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ (RSS ê¸°ë°˜)\n\n"
    headlines = data.get("headlines", [])
    if headlines:
        for idx, headline in enumerate(headlines, 1):
            news_section += f"[{idx}] **{headline.get('title')}**\n"
            news_section += f"   - ì¶œì²˜: {headline.get('source')}\n"
            news_section += f"   - ë§í¬: {headline.get('url')}\n"
            news_section += f"   - ë‚ ì§œ: {headline.get('date', 'N/A')}\n\n"
    else:
        news_section += "âš ï¸ RSS ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ (ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜)\n\n"
    
    user = f"""
ì•„ë˜ JSONê³¼ RSS ë‰´ìŠ¤ ë§í¬ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±:

## ì œê³µëœ ë°ì´í„°
{data}

{news_section}

[TASK]
1) 3~5ë¬¸ë‹¨ ìš”ì•½ (RSS ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì„ ì°¸ê³ í•˜ì—¬ í˜„ì¬ ì‹œì¥ ìƒí™© ì„¤ëª…).
2) í•µì‹¬ ë°ì´í„° í‘œ (ì§€í‘œ/ìˆ˜ì¹˜/ì „ê¸°Â·ì „ë…„ë¹„/ì»¨ì„¼ì„œìŠ¤/ì½”ë©˜íŠ¸).
3) ê±°ì‹œ í•´ì„ (ì¸í”Œë ˆ/ì„±ì¥/ê³ ìš©/ì •ì±… ê° 2~3ë¬¸ì¥, RSS ë‰´ìŠ¤ì™€ ì—°ê²°).
4) ì‹œì¥ ë°˜ì‘ & ê´€ì „ í¬ì¸íŠ¸ (RSS ë‰´ìŠ¤ì—ì„œ ì–¸ê¸‰ëœ ì´ìŠˆ ì¤‘ì‹¬).
5) ë¦¬ìŠ¤í¬ Top 3 (êµ¬ì²´ì  ì‹œë‚˜ë¦¬ì˜¤).
6) ì‚¬ìš©ì ë§ì¶¤ ì½”ë©˜íŠ¸ (ê´€ì‹¬ ì„¹í„°: ë°˜ë„ì²´, ë¶€ë™ì‚°. ê³¼í•œ í™•ì‹  ê¸ˆì§€).
7) ì°¸ê³  ë§í¬: ìœ„ RSS ë‰´ìŠ¤ë¥¼ [1], [2], [3]... í˜•íƒœë¡œ ë³¸ë¬¸ì— ì¸ìš©.
8) ë§ˆì§€ë§‰ì— "### ğŸ“° ë‰´ìŠ¤ ì¶œì²˜" ì„¹ì…˜ì„ ì¶”ê°€í•˜ì—¬ ëª¨ë“  ë§í¬ ë‚˜ì—´.

í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì¶œë ¥í•˜ë˜, ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±.
"""
    return system, user

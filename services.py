import os, datetime as dt, math
import httpx
import feedparser
from openai import OpenAI

OPENAI = os.getenv("OPENAI_API_KEY")
CHAT_MODEL = os.getenv("CHAT_MODEL", "gpt-4o-mini")
ECOS_KEY = os.getenv("ECOS_KEY")
FRED_KEY = os.getenv("FRED_KEY")

# ---------------- RSS ë‰´ìŠ¤ ìˆ˜ì§‘ (ë¬´ë£Œ) ----------------
async def fetch_rss_news(kind: str) -> list[dict]:
    """
    RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    Fallback: ë„¤íŠ¸ì›Œí¬ ì‹¤íŒ¨ ì‹œ stub ë°ì´í„° ë°˜í™˜
    """
    news_sources = []
    
    try:
        # 1. ì—°í•©ë‰´ìŠ¤ RSS
        yna_feed = feedparser.parse("https://www.yna.co.kr/rss/all.xml")
        for entry in yna_feed.entries[:5]:
            news_sources.append({
                "title": entry.get("title", "ì œëª© ì—†ìŒ"),
                "url": entry.get("link", ""),
                "source": "ì—°í•©ë‰´ìŠ¤",
                "date": entry.get("published", "")
            })
    except Exception as e:
        print(f"ì—°í•©ë‰´ìŠ¤ RSS ì˜¤ë¥˜: {e}")
    
    try:
        # 2. í•œêµ­ê²½ì œ RSS
        hankyung_feed = feedparser.parse("https://www.hankyung.com/feed/")
        for entry in hankyung_feed.entries[:5]:
            news_sources.append({
                "title": entry.get("title", "ì œëª© ì—†ìŒ"),
                "url": entry.get("link", ""),
                "source": "í•œêµ­ê²½ì œ",
                "date": entry.get("published", "")
            })
    except Exception as e:
        print(f"í•œêµ­ê²½ì œ RSS ì˜¤ë¥˜: {e}")
    
    try:
        # 3. Google News RSS (ê²½ì œ í‚¤ì›Œë“œ)
        if kind == "daily":
            query = "KOSPI OR KOSDAQ OR í•œêµ­ê²½ì œ OR ì¦ì‹œ"
        elif kind == "weekly":
            query = "ìˆ˜ì¶œ OR ë¬´ì—­ OR ì‚°ì—…ë™í–¥"
        else:
            query = "ê²½ì œì „ë§ OR ê¸ˆë¦¬ OR ì¸í”Œë ˆì´ì…˜"
        
        google_url = f"https://news.google.com/rss/search?q={query}&hl=ko&gl=KR&ceid=KR:ko"
        google_feed = feedparser.parse(google_url)
        for entry in google_feed.entries[:5]:
            news_sources.append({
                "title": entry.get("title", "ì œëª© ì—†ìŒ"),
                "url": entry.get("link", ""),
                "source": "Google News",
                "date": entry.get("published", "")
            })
    except Exception as e:
        print(f"Google News RSS ì˜¤ë¥˜: {e}")
    
    # Fallback: stub ë°ì´í„°
    if not news_sources:
        print("ëª¨ë“  RSS í”¼ë“œ ì‹¤íŒ¨ - stub ë°ì´í„° ì‚¬ìš©")
        return [
            {"title": "[ìŠ¤í…] í•œêµ­ CPI 3.2% ê¸°ë¡, ì˜ˆìƒì¹˜ ìƒíšŒ", "url": "https://example.com/kcpi", "source": "stub", "date": dt.datetime.now().isoformat()},
            {"title": "[ìŠ¤í…] ì½”ìŠ¤í”¼ ì™¸êµ­ì¸ ìˆœë§¤ë„ ì§€ì†", "url": "https://example.com/kospi", "source": "stub", "date": dt.datetime.now().isoformat()},
            {"title": "[ìŠ¤í…] ë¯¸ ì—°ì¤€ ê¸ˆë¦¬ ë™ê²° ê²°ì •", "url": "https://example.com/fed", "source": "stub", "date": dt.datetime.now().isoformat()},
            {"title": "[ìŠ¤í…] ì„œìš¸ ì•„íŒŒíŠ¸ ë§¤ë§¤ê°€ 6ì£¼ ì—°ì† ìƒìŠ¹", "url": "https://example.com/apt", "source": "stub", "date": dt.datetime.now().isoformat()},
        ]
    
    return news_sources[:10]  # ìµœëŒ€ 10ê°œ ë°˜í™˜

# ---------------- FRED helpers ----------------
async def fred_latest(series_id: str):
    if not FRED_KEY: return None
    url = f"https://api.stlouisfed.org/fred/series/observations?series_id={series_id}&api_key={FRED_KEY}&file_type=json&sort_order=desc&limit=1"
    try:
        async with httpx.AsyncClient(timeout=20) as client:
            r = await client.get(url)
            r.raise_for_status()
            j = r.json()
        obs = j.get("observations", [])
        if not obs: return None
        o = obs[0]
        return {"date": o.get("date"), "value": o.get("value")}
    except Exception as e:
        print(f"FRED API ì˜¤ë¥˜ ({series_id}): {e}")
        return None

async def enrich_with_fred(data: dict) -> dict:
    dgs10 = await fred_latest("DGS10")
    if dgs10 and dgs10["value"] not in (None, "."):
        data.setdefault("daily_snapshot", {}).setdefault("rates", {})["UST10Y"] = float(dgs10["value"])
    krw = await fred_latest("DEXKOUS")
    if krw and krw["value"] not in (None, "."):
        data.setdefault("daily_snapshot", {}).setdefault("fx", {})["USDKRW"] = float(krw["value"])
    cpi = await fred_latest("CPIAUCSL")
    if cpi and cpi["value"] not in (None, "."):
        data.setdefault("macro", []).append({"name":"US CPI (index)", "latest": float(cpi["value"]), "note": cpi["date"]})
    unrate = await fred_latest("UNRATE")
    if unrate and unrate["value"] not in (None, "."):
        data.setdefault("macro", []).append({"name":"US Unemployment Rate", "latest": float(unrate["value"]), "note": unrate["date"]})
    ffr = await fred_latest("FEDFUNDS")
    if ffr and ffr["value"] not in (None, "."):
        data.setdefault("macro", []).append({"name":"Fed Funds Rate", "latest": float(ffr["value"]), "note": ffr["date"]})
    korcpi = await fred_latest("KORCPIALLMINMEI")
    if korcpi and korcpi["value"] not in (None, "."):
        data.setdefault("macro", []).append({"name":"Korea CPI (OECD/FRED)", "latest": float(korcpi["value"]), "note": korcpi["date"]})
    return data

# ---------------- ECOS(ì˜µì…˜) ----------------
async def ecos_korea_cpi_latest():
    if not ECOS_KEY: return None
    url = f"https://ecos.bok.or.kr/api/StatisticSearch/{ECOS_KEY}/json/kr/1/2/901Y014/M/2020/2030/"
    try:
        async with httpx.AsyncClient(timeout=20) as client:
            r = await client.get(url)
            r.raise_for_status()
            j = r.json()
        row = j["StatisticSearch"]["row"][-1]
        return {"value": float(row["DATA_VALUE"]), "date": row["TIME"]}
    except Exception as e:
        print(f"ECOS API ì˜¤ë¥˜: {e}")
        return None

async def enrich_with_ecos(data: dict) -> dict:
    kcpi = await ecos_korea_cpi_latest()
    if kcpi:
        data.setdefault("macro", []).append({"name":"Korea CPI (ECOS)", "latest": kcpi["value"], "note": kcpi["date"]})
    return data

# ---------------- ì…ë ¥ ë°ì´í„° êµ¬ì„± ----------------
async def build_inputs(kind: str) -> dict:
    today = dt.datetime.now().date().isoformat()
    
    # RSS ë‰´ìŠ¤ ìˆ˜ì§‘
    headlines = await fetch_rss_news(kind)
    
    data = {
        "date": today,
        "daily_snapshot": {
            "indices": {"KOSPI": 2640.0, "KOSDAQ": 850.0, "S&P500": 5350.0, "Nasdaq": 17000.0, "Dow": 39000.0},
            "fx": {"USDKRW": 1390.0},
            "rates": {"UST10Y": 4.4, "KR3Y": 3.5},
            "commodities": {"WTI": 78.5, "Brent": 82.0, "Gold": 2350.0}
        },
        "macro": [
            {"name": "Korea CPI (stub)", "latest": 3.2, "prev": 3.0, "consensus": 3.1, "yoy": 3.2},
            {"name": "US CPI (stub)", "latest": 3.4, "consensus": 3.4, "core": 3.8}
        ],
        "headlines": headlines,
        "user_profile": {"risk_pref": "ì¤‘ë¦½", "interests": ["ë°˜ë„ì²´", "ë¶€ë™ì‚°"]}
    }
    
    # ì‹¤ë°ì´í„° ë³´ê°•
    data = await enrich_with_fred(data)
    data = await enrich_with_ecos(data)
    
    return data

# ---------------- LLM í˜¸ì¶œ ----------------
async def call_llm(system_prompt: str, user_prompt: str) -> str:
    if not OPENAI:
        return (
            "**ìš”ì•½**: (ìŠ¤í…) ë¬¼ê°€ ë‘”í™” ê¸°ëŒ€ì™€ ì •ì±… ë¶ˆí™•ì‹¤ì„± í˜¼ì¬.\n\n"
            "**í•µì‹¬ ë°ì´í„°**\n\n"
            "|ì§€í‘œ|ìˆ˜ì¹˜|ì „ì›”/ì „ë…„|ì»¨ì„¼ì„œìŠ¤|ì½”ë©˜íŠ¸|\n"
            "|---|---:|---:|---:|---|\n"
            "|Korea CPI|3.2%|+0.2%p|3.1%|ì‹ë£ŒÂ·ì—ë„ˆì§€ ì˜í–¥|\n"
            "|US CPI|3.4%|-|3.4%|ê·¼ì› ë†’ì€ í¸|\n\n"
            "**í•´ì„**: (ìŠ¤í…) ê¸´ì¶• ì¥ê¸°í™” ë¦¬ìŠ¤í¬.\n\n"
            "**ì‹œì¥ ë°˜ì‘**: (ìŠ¤í…) ë‚˜ìŠ¤ë‹¥ ì•½ì„¸, ì›/ë‹¬ëŸ¬ ê°•ì„¸.\n\n"
            "**ë¦¬ìŠ¤í¬ Top3**: (1) ì¸í”Œë ˆ ì¬ê°€ì† (2) ë‹¬ëŸ¬ ê°•ì„¸ (3) ì§€ì •í•™.\n\n"
            "**ë§ì¶¤ ì½”ë©˜íŠ¸**: ë°˜ë„ì²´ ë‹¨ê¸° ë³€ë™ì„± ì£¼ì˜, ì£¼íƒì€ ê¸ˆë¦¬ í”¼í¬ì•„ì›ƒ í™•ì¸í›„ ì ‘ê·¼."
        )
    
    try:
        client = OpenAI(api_key=OPENAI)
        resp = client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3
        )
        return resp.choices[0].message.content
    except Exception as e:
        print(f"OpenAI API ì˜¤ë¥˜: {e}")
        return f"**ì˜¤ë¥˜**: OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ - {str(e)}\n\n(ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤)"

# ---------------- í•´ì„ í”„ë¡¬í”„íŠ¸ ----------------
def build_analysis_prompt(data: dict) -> tuple[str, str]:
    system = (
        "You are a Korean macro & markets analyst for one user (Junki). "
        "Style: concise, neutral, actionable. Explain terms briefly. "
        "Ground claims in provided data and links."
    )
    
    # ë‰´ìŠ¤ í—¤ë“œë¼ì¸ í¬ë§·íŒ…
    news_section = "\n\n### ğŸ“° ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ (RSS ê¸°ë°˜)\n\n"
    for idx, headline in enumerate(data.get("headlines", []), 1):
        news_section += f"[{idx}] **{headline.get('title')}**\n"
        news_section += f"   - ì¶œì²˜: {headline.get('source')}\n"
        news_section += f"   - ë§í¬: {headline.get('url')}\n"
        news_section += f"   - ë‚ ì§œ: {headline.get('date', 'N/A')}\n\n"
    
    user = f"""
ì•„ë˜ JSONê³¼ RSS ë‰´ìŠ¤ ë§í¬ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±:

## ì œê³µëœ ë°ì´í„°
{data}

{news_section}

[TASK]
1) 3~5ë¬¸ë‹¨ ìš”ì•½ (RSS ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì„ ì°¸ê³ í•˜ì—¬ í˜„ì¬ ì‹œì¥ ìƒí™© ì„¤ëª…).
2) í•µì‹¬ ë°ì´í„° í‘œ (ì§€í‘œ/ìˆ˜ì¹˜/ì „ê¸°Â·ì „ë…„ë¹„/ì»¨ì„¼ì„œìŠ¤/ì½”ë©˜íŠ¸).
3) ê±°ì‹œ í•´ì„ (ì¸í”Œë ˆ/ì„±ì¥/ê³ ìš©/ì •ì±… ê° 2~3ë¬¸ì¥, RSS ë‰´ìŠ¤ì™€ ì—°ê²°).
4) ì‹œì¥ ë°˜ì‘ & ê´€ì „ í¬ì¸íŠ¸ (RSS ë‰´ìŠ¤ì—ì„œ ì–¸ê¸‰ëœ ì´ìŠˆ ì¤‘ì‹¬).
5) ë¦¬ìŠ¤í¬ Top 3 (êµ¬ì²´ì  ì‹œë‚˜ë¦¬ì˜¤).
6) ì‚¬ìš©ì ë§ì¶¤ ì½”ë©˜íŠ¸ (ê´€ì‹¬ ì„¹í„°: ë°˜ë„ì²´, ë¶€ë™ì‚°. ê³¼í•œ í™•ì‹  ê¸ˆì§€).
7) ì°¸ê³  ë§í¬: ìœ„ RSS ë‰´ìŠ¤ë¥¼ [1], [2], [3]... í˜•íƒœë¡œ ë³¸ë¬¸ì— ì¸ìš©.
8) ë§ˆì§€ë§‰ì— "### ğŸ“° ë‰´ìŠ¤ ì¶œì²˜" ì„¹ì…˜ì„ ì¶”ê°€í•˜ì—¬ ëª¨ë“  ë§í¬ ë‚˜ì—´.

í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì¶œë ¥í•˜ë˜, ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±.
"""
    return system, user
